{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66242d2f",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db14a1",
   "metadata": {},
   "source": [
    "Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5de71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DJNaj\\Documents\\CiTG\\MSc\\Year II\\Q2\\CEGM2003 - Data Science and Artificial Intelligence for Engineers\\Unit 3 - Project\\FLOOD_group2\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "# move to the root directory of the git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df834647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import random\n",
    "\n",
    "from pre_processing.process_data import *\n",
    "from models.CNN_model.CNN_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ccc13",
   "metadata": {},
   "source": [
    "# Creating Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8168f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the time t0 and t\n",
    "t0 = 0\n",
    "t = 1\n",
    "\n",
    "train_dataset = []\n",
    "\n",
    "for i in range(1, 81):  # Loop through file IDs from DEM_1 to DEM_80\n",
    "    file_id = i\n",
    "    \n",
    "    # Input Tensor (input_tensor.shape will be [4, 64, 64])\n",
    "    elevation_slope_tensor = process_elevation_data(file_id, dataset_id='train/val')\n",
    "    water_depth_input_tensor = process_water_depth(file_id, dataset_id='train/val', time_step=t0)  # Time Step is t0\n",
    "    water_depth_input_tensor = torch.unsqueeze(water_depth_input_tensor, 0)\n",
    "    \n",
    "    input_tensor = torch.cat((elevation_slope_tensor, water_depth_input_tensor), dim=0)\n",
    "    input_tensor = input_tensor.double()\n",
    "    \n",
    "    # Output Sequence Tensor (output_sequence_tensor.shape will be [48, 64, 64])\n",
    "    output_tensors = []\n",
    "    for time_step_index in range(1, 96, 2):  # Loop through every even time step out of the 96\n",
    "        water_depth_output_tensor = process_water_depth(file_id, dataset_id='train/val', time_step=t0 + time_step_index)\n",
    "        output_tensors.append(water_depth_output_tensor)\n",
    "    \n",
    "    output_sequence_tensor = torch.stack(output_tensors, dim=0)\n",
    "    output_sequence_tensor = output_sequence_tensor.double()\n",
    "    \n",
    "    # Create a tuple\n",
    "    train_dataset_sample = (input_tensor, output_sequence_tensor)\n",
    "    \n",
    "    # Append the sample to the train_dataset list\n",
    "    train_dataset.append(train_dataset_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d940397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Input Train Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Train Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n",
      "Sample 2:\n",
      "Input Train Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Train Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n",
      "Sample 3:\n",
      "Input Train Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Train Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n",
      "Sample 4:\n",
      "Input Train Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Train Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n",
      "Sample 5:\n",
      "Input Train Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Train Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing a few samples to verify the shape of train input and output tensors\n",
    "\n",
    "for i, sample in enumerate(train_dataset[:5]):  # Print shapes for the first 5 samples\n",
    "    input_train_tensor, output_train_sequence_tensor = sample\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(\"Input Train Tensor Shape:\", input_train_tensor.shape)\n",
    "    print(\"Output Train Sequence Tensor Shape:\", output_train_sequence_tensor.shape)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7bb7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select a random sample from the dataset\n",
    "# sample_index = random.randint(0, len(train_dataset) - 1)\n",
    "# print(sample_index)\n",
    "# input_tensor, output_sequence_tensor = train_dataset[sample_index]\n",
    "\n",
    "# # Plot input tensors (DEM, slope x, slope y, water depth at initial time step)\n",
    "# fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "# # Plot DEM (Terrain) with appropriate colormap\n",
    "# axs[0].imshow(input_tensor[0], cmap='terrain')\n",
    "# axs[0].set_title('DEM (Terrain)')\n",
    "\n",
    "# # Plot slope x and slope y with 'coolwarm' colormap\n",
    "# for i in range(1, 3):\n",
    "#     axs[i].imshow(input_tensor[i], cmap='coolwarm')\n",
    "#     axs[i].set_title(f'Slope {\"X\" if i == 1 else \"Y\"}')\n",
    "\n",
    "# # Plot water depth at initial time step and output at a random time step with 'Blues' colormap\n",
    "# axs[3].imshow(input_tensor[3], cmap='Blues')\n",
    "# axs[3].set_title('Water Depth (Initial Time Step)')\n",
    "\n",
    "# # Select a random time step from the output sequence tensor\n",
    "# random_time_step = random.randint(0, output_sequence_tensor.shape[0] - 1)\n",
    "# output_at_time_step = output_sequence_tensor[random_time_step]\n",
    "\n",
    "# # Plot the output at the random time step\n",
    "# axs[4].imshow(output_at_time_step, cmap='Blues')\n",
    "# axs[4].set_title(f'Output at Time Step {random_time_step}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b9533",
   "metadata": {},
   "source": [
    "# Creating the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ddedcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the time t0 and t\n",
    "t0 = 0\n",
    "t = 1\n",
    "\n",
    "# Loop through file IDs from DEM_1 to DEM_80\n",
    "test_dataset = []\n",
    "\n",
    "for i in range(500, 520):  # Assuming file IDs are numbered from 500 to 520\n",
    "    file_id = i\n",
    "    \n",
    "    # Input Tensor (input_tensor.shape will be [4, 64, 64])\n",
    "    elevation_slope_tensor = process_elevation_data(file_id, dataset_id='dataset1')\n",
    "    water_depth_input_tensor = process_water_depth(file_id, dataset_id='dataset1', time_step=t0)  # Time Step is t0\n",
    "    # Add an extra dimension to make water_depth_tensor [1, 64, 64]\n",
    "    water_depth_input_tensor = torch.unsqueeze(water_depth_input_tensor, 0)\n",
    "    \n",
    "    # Concatenate to create the input tensor\n",
    "    input_test_tensor = torch.cat((elevation_slope_tensor, water_depth_input_tensor), dim=0)\n",
    "    input_test_tensor = input_test_tensor.double()\n",
    "    \n",
    "    # Output Sequence Tensor (output_sequence_tensor.shape will be [48, 64, 64])\n",
    "    output_test_tensors = []\n",
    "    for time_step_index in range(1,96,2):  # Loop through every even time step out of the 96\n",
    "        water_depth_output_tensor = process_water_depth(file_id, dataset_id='dataset1', time_step=t0 + time_step_index)\n",
    "        output_test_tensors.append(water_depth_output_tensor)\n",
    "    \n",
    "    # Stack the list of output tensors along the new time dimension to create a sequence\n",
    "    output_test_sequence_tensor = torch.stack(output_test_tensors, dim=0)\n",
    "    output_test_sequence_tensor = output_test_sequence_tensor.double()\n",
    "    \n",
    "    # Create a tuple\n",
    "    test_dataset_sample = (input_test_tensor, output_test_sequence_tensor)\n",
    "    \n",
    "    # Append the sample to the test_dataset list\n",
    "    test_dataset.append(test_dataset_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a7ec89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Input Test Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Test Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n",
      "Sample 2:\n",
      "Input Test Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Test Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n",
      "Sample 3:\n",
      "Input Test Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Test Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n",
      "Sample 4:\n",
      "Input Test Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Test Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n",
      "Sample 5:\n",
      "Input Test Tensor Shape: torch.Size([4, 64, 64])\n",
      "Output Test Sequence Tensor Shape: torch.Size([48, 64, 64])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing a few samples to verify the shape of test input and output tensors\n",
    "\n",
    "for i, sample in enumerate(test_dataset[:5]):  # Print shapes for the first 5 samples\n",
    "    input_test_tensor, output_test_sequence_tensor = sample\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(\"Input Test Tensor Shape:\", input_test_tensor.shape)\n",
    "    print(\"Output Test Sequence Tensor Shape:\", output_test_sequence_tensor.shape)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8188290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select a random sample from the dataset\n",
    "# sample_index = random.randint(0, len(test_dataset) - 1)\n",
    "# input_test_tensor, output_test_sequence_tensor = test_dataset[sample_index]\n",
    "\n",
    "# # Plot input tensors (DEM, slope x, slope y, water depth at initial time step)\n",
    "# fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "# # Plot DEM (Terrain) with appropriate colormap\n",
    "# axs[0].imshow(input_tensor[0], cmap='terrain')\n",
    "# axs[0].set_title('DEM (Terrain)')\n",
    "\n",
    "# # Plot slope x and slope y with 'coolwarm' colormap\n",
    "# for i in range(1, 3):\n",
    "#     axs[i].imshow(input_test_tensor[i], cmap='coolwarm')\n",
    "#     axs[i].set_title(f'Slope {\"X\" if i == 1 else \"Y\"}')\n",
    "\n",
    "# # Plot water depth at initial time step and output at a random time step with 'Blues' colormap\n",
    "# axs[3].imshow(input_test_tensor[3], cmap='Blues')\n",
    "# axs[3].set_title('Water Depth (Initial Time Step)')\n",
    "\n",
    "# # Select a random time step from the output sequence tensor\n",
    "# random_time_step = random.randint(0, output_sequence_tensor.shape[0] - 1)\n",
    "# output_test_at_time_step = output_test_sequence_tensor[random_time_step]\n",
    "\n",
    "# # Plot the output at the random time step\n",
    "# axs[4].imshow(output_test_at_time_step, cmap='Blues')\n",
    "# axs[4].set_title(f'Output at Time Step {random_time_step}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e01e5",
   "metadata": {},
   "source": [
    "# Normalizing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2ceb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_dataset(dataset, scaler_x, scaler_y):\n",
    "#     # Extract min and max values from the scalers for inputs and outputs\n",
    "#     min_x, max_x = scaler_x.data_min_[0], scaler_x.data_max_[0]\n",
    "#     min_y, max_y = scaler_y.data_min_[0], scaler_y.data_max_[0]\n",
    "\n",
    "#     normalized_dataset = []\n",
    "#     for idx in range(len(dataset)):\n",
    "#         x = dataset[idx][0]\n",
    "#         y_sequence = dataset[idx][1]\n",
    "\n",
    "#         # Normalize input (assuming it's a single tensor)\n",
    "#         norm_x = (x - min_x) / (max_x - min_x)\n",
    "\n",
    "#         # Normalize each output sequence tensor individually\n",
    "#         normalized_sequence = []\n",
    "#         for t in range(y_sequence.shape[0]):\n",
    "#             norm_y = (y_sequence[t] - min_y) / (max_y - min_y)\n",
    "#             normalized_sequence.append(norm_y)\n",
    "\n",
    "#         normalized_dataset.append((norm_x, torch.stack(normalized_sequence)))\n",
    "\n",
    "#     return normalized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e761bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_x = MinMaxScaler()\n",
    "# scaler_y = MinMaxScaler()\n",
    "\n",
    "# # Fit the scalers using the training dataset\n",
    "# for idx in range(len(train_dataset)):\n",
    "#     scaler_x.partial_fit(train_dataset[idx][0].flatten().unsqueeze(0).T.cpu())\n",
    "#     scaler_y.partial_fit(train_dataset[idx][1].flatten().unsqueeze(0).T.cpu())\n",
    "\n",
    "# # Normalize the datasets\n",
    "# normalized_train_dataset = normalize_dataset(train_dataset, scaler_x, scaler_y)\n",
    "# normalized_test_dataset = normalize_dataset(test_dataset, scaler_x, scaler_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f06cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming normalized_train_dataset and normalized_test_dataset are your normalized datasets\n",
    "\n",
    "# # Print the minimum and maximum values for input and output sequences in the first sample of the normalized training dataset\n",
    "# input_sample, output_sample = normalized_train_dataset[0]\n",
    "# print(\"Input Min-Max:\", input_sample[0].min().item(), \"-\", input_sample[0].max().item())\n",
    "# print(\"Output Min-Max:\", output_sample.min().item(), \"-\", output_sample.max().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5aeda4",
   "metadata": {},
   "source": [
    "# Splitting the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95a6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = 0.8\n",
    "train_size = int(train_percent * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc5614",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96941b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 64, 64]           4,608\n",
      "       BatchNorm2d-2          [-1, 128, 64, 64]             256\n",
      "              ReLU-3          [-1, 128, 64, 64]               0\n",
      "            Conv2d-4          [-1, 128, 64, 64]         147,456\n",
      "       BatchNorm2d-5          [-1, 128, 64, 64]             256\n",
      "              ReLU-6          [-1, 128, 64, 64]               0\n",
      "        DoubleConv-7          [-1, 128, 64, 64]               0\n",
      "         MaxPool2d-8          [-1, 128, 32, 32]               0\n",
      "            Conv2d-9          [-1, 256, 32, 32]         294,912\n",
      "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
      "             ReLU-11          [-1, 256, 32, 32]               0\n",
      "           Conv2d-12          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-13          [-1, 256, 32, 32]             512\n",
      "             ReLU-14          [-1, 256, 32, 32]               0\n",
      "       DoubleConv-15          [-1, 256, 32, 32]               0\n",
      "             Down-16          [-1, 256, 32, 32]               0\n",
      "        MaxPool2d-17          [-1, 256, 16, 16]               0\n",
      "           Conv2d-18          [-1, 512, 16, 16]       1,179,648\n",
      "      BatchNorm2d-19          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-20          [-1, 512, 16, 16]               0\n",
      "           Conv2d-21          [-1, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-22          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-23          [-1, 512, 16, 16]               0\n",
      "       DoubleConv-24          [-1, 512, 16, 16]               0\n",
      "             Down-25          [-1, 512, 16, 16]               0\n",
      "        MaxPool2d-26            [-1, 512, 8, 8]               0\n",
      "           Conv2d-27           [-1, 1024, 8, 8]       4,718,592\n",
      "      BatchNorm2d-28           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-29           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-30           [-1, 1024, 8, 8]       9,437,184\n",
      "      BatchNorm2d-31           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-32           [-1, 1024, 8, 8]               0\n",
      "       DoubleConv-33           [-1, 1024, 8, 8]               0\n",
      "             Down-34           [-1, 1024, 8, 8]               0\n",
      "        MaxPool2d-35           [-1, 1024, 4, 4]               0\n",
      "           Conv2d-36           [-1, 2048, 4, 4]      18,874,368\n",
      "      BatchNorm2d-37           [-1, 2048, 4, 4]           4,096\n",
      "             ReLU-38           [-1, 2048, 4, 4]               0\n",
      "           Conv2d-39           [-1, 2048, 4, 4]      37,748,736\n",
      "      BatchNorm2d-40           [-1, 2048, 4, 4]           4,096\n",
      "             ReLU-41           [-1, 2048, 4, 4]               0\n",
      "       DoubleConv-42           [-1, 2048, 4, 4]               0\n",
      "             Down-43           [-1, 2048, 4, 4]               0\n",
      "  ConvTranspose2d-44           [-1, 1024, 8, 8]       8,389,632\n",
      "           Conv2d-45           [-1, 1024, 8, 8]      18,874,368\n",
      "      BatchNorm2d-46           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-47           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-48           [-1, 1024, 8, 8]       9,437,184\n",
      "      BatchNorm2d-49           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-50           [-1, 1024, 8, 8]               0\n",
      "       DoubleConv-51           [-1, 1024, 8, 8]               0\n",
      "               Up-52           [-1, 1024, 8, 8]               0\n",
      "  ConvTranspose2d-53          [-1, 512, 16, 16]       2,097,664\n",
      "           Conv2d-54          [-1, 512, 16, 16]       4,718,592\n",
      "      BatchNorm2d-55          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-56          [-1, 512, 16, 16]               0\n",
      "           Conv2d-57          [-1, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-58          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-59          [-1, 512, 16, 16]               0\n",
      "       DoubleConv-60          [-1, 512, 16, 16]               0\n",
      "               Up-61          [-1, 512, 16, 16]               0\n",
      "  ConvTranspose2d-62          [-1, 256, 32, 32]         524,544\n",
      "           Conv2d-63          [-1, 256, 32, 32]       1,179,648\n",
      "      BatchNorm2d-64          [-1, 256, 32, 32]             512\n",
      "             ReLU-65          [-1, 256, 32, 32]               0\n",
      "           Conv2d-66          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-67          [-1, 256, 32, 32]             512\n",
      "             ReLU-68          [-1, 256, 32, 32]               0\n",
      "       DoubleConv-69          [-1, 256, 32, 32]               0\n",
      "               Up-70          [-1, 256, 32, 32]               0\n",
      "  ConvTranspose2d-71          [-1, 128, 64, 64]         131,200\n",
      "           Conv2d-72          [-1, 128, 64, 64]         294,912\n",
      "      BatchNorm2d-73          [-1, 128, 64, 64]             256\n",
      "             ReLU-74          [-1, 128, 64, 64]               0\n",
      "           Conv2d-75          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-76          [-1, 128, 64, 64]             256\n",
      "             ReLU-77          [-1, 128, 64, 64]               0\n",
      "       DoubleConv-78          [-1, 128, 64, 64]               0\n",
      "               Up-79          [-1, 128, 64, 64]               0\n",
      "           Conv2d-80           [-1, 48, 64, 64]           6,192\n",
      "          OutConv-81           [-1, 48, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 124,128,688\n",
      "Trainable params: 124,128,688\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 130.38\n",
      "Params size (MB): 473.51\n",
      "Estimated Total Size (MB): 603.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the CNN architecture\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=4, n_classes=48, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 128))\n",
    "        self.down1 = (Down(128, 256))\n",
    "        self.down2 = (Down(256, 512))\n",
    "        self.down3 = (Down(512, 1024))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(1024, 2048 // factor))\n",
    "        self.up1 = (Up(2048, 1024 // factor, bilinear))\n",
    "        self.up2 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up3 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up4 = (Up(256, 128, bilinear))\n",
    "        self.outc = (OutConv(128, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)\n",
    "\n",
    "# Instantiate the CNN\n",
    "model = UNet().to(device)  # Replace with your model and number of classes\n",
    "summary(model, input_size=(4, 64, 64)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9527fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the optimizer to train the neural network via back-propagation\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training and validation dataloaders to \"feed\" data to the model in batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0421294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.0703 | Validation Loss: 82.0819\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device=device)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    validation_loss = evaluation(model, val_loader, device=device)\n",
    "    validation_losses.append(validation_loss)\n",
    "\n",
    "    # Print the loss for every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Validation Loss: {validation_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluation(model, test_loader, device=device)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03951c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training')\n",
    "plt.plot(validation_losses, label='Validation')\n",
    "plt.yscale('log')\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22348abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one sample\n",
    "data_id = 2\n",
    "\n",
    "x = test_dataset[data_id][0].unsqueeze(0)\n",
    "x = x.float().to(device)\n",
    "WD = test_dataset[data_id][1]\n",
    "\n",
    "# Display the shapes of the input data and water depth tensor\n",
    "print(f\"Shape of input data (x): {x.shape}\")\n",
    "print(f\"Shape of water depth (WD): {WD.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the first plot represents terrain, and the subsequent plots use different colormaps\n",
    "colormaps = ['terrain', 'coolwarm', 'coolwarm', 'Blues']\n",
    "\n",
    "# Define titles for each channel\n",
    "channel_titles = ['DEM', 'Slope X', 'Slope Y', f'Water Depth t={t0}']\n",
    "\n",
    "# Plotting the input tensor (x)\n",
    "x_np = x.squeeze(0).cpu().numpy()  # Convert tensor to NumPy array and remove the batch dimension\n",
    "num_channels = x_np.shape[0]  # Number of channels in the input\n",
    "\n",
    "# Plot each channel separately with different colormaps and titles\n",
    "fig, axs = plt.subplots(1, num_channels, figsize=(4 * num_channels, 4))\n",
    "for i in range(num_channels):\n",
    "    axs[i].imshow(x_np[i], cmap=colormaps[i], origin='lower')  # Set origin to lower left and use different colormaps\n",
    "    axs[i].set_title(channel_titles[i])  # Set individual titles for each channel\n",
    "plt.suptitle(f'Test Sample: {data_id}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the WD tensor\n",
    "WD_np = WD.cpu().numpy()  # Convert tensor to NumPy array\n",
    "\n",
    "# Assuming WD is a sequence of images (96 time steps)\n",
    "num_time_steps = WD_np.shape[0]\n",
    "\n",
    "# Plotting specific time steps (e.g., every 10th time step)\n",
    "time_steps_to_plot = list(range(0, num_time_steps, 10))\n",
    "\n",
    "fig, axs = plt.subplots(1, len(time_steps_to_plot), figsize=(4 * len(time_steps_to_plot), 4))\n",
    "for i, timestep in enumerate(time_steps_to_plot):\n",
    "    axs[i].imshow(WD_np[timestep], cmap='Blues', origin='lower')  # Set origin to lower left\n",
    "    axs[i].set_title(f\"Time Step {timestep + 1}\")\n",
    "plt.suptitle(\"Water Depth (WD) at Specific Time Steps\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the WD\n",
    "pred_WD = model(x).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f08f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted tensor to numpy array\n",
    "pred_WD_np = pred_WD.squeeze(0).cpu().numpy()  # Assuming batch dimension needs to be squeezed\n",
    "\n",
    "# Plotting specific time steps (e.g., every 10th time step)\n",
    "time_steps_to_plot_pred = list(range(0, pred_WD_np.shape[0], 10))\n",
    "\n",
    "fig, axs = plt.subplots(1, len(time_steps_to_plot_pred), figsize=(4 * len(time_steps_to_plot_pred), 4))\n",
    "for i, timestep in enumerate(time_steps_to_plot_pred):\n",
    "    axs[i].imshow(pred_WD_np[timestep], cmap='Blues', origin='lower')  # Assuming 'viridis' colormap, change as needed\n",
    "    axs[i].set_title(f\"Predicted Time Step {timestep + 1}\")\n",
    "plt.suptitle(f'Predicted Water Depth at Specific Time Steps for Test Sample: {data_id}')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf0fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshaping for the case of 96 timesteps\n",
    "# DEM = scaler_x.inverse_transform(x[0].reshape(4, -1).T.cpu())[:, 0].reshape(64, 64)\n",
    "# real_WD = scaler_y.inverse_transform(WD.reshape(96, -1).cpu()).reshape(96, 64, 64)\n",
    "# pred_WD = scaler_y.inverse_transform(pred_WD.reshape(96, -1).cpu()).reshape(96, 64, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming pred_WD contains the predicted water depths with shape (96, 64, 64)\n",
    "# num_time_steps = 4  # Number of time steps to plot\n",
    "\n",
    "# fig, axs = plt.subplots(1, num_time_steps, figsize=(12, 3))\n",
    "\n",
    "# for i in range(num_time_steps):\n",
    "#     axs[i].imshow(pred_WD[i], cmap='viridis')  # Adjust the colormap as needed\n",
    "#     axs[i].set_title(f\"Time Step {i+1}\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021482fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming pred_WD contains the predicted water depths with shape (96, 64, 64)\n",
    "# num_time_steps = 50  # Number of time steps to plot\n",
    "# sample_index = 0  # Index of the sample to visualize\n",
    "\n",
    "# fig, axs = plt.subplots(5, 10, figsize=(15, 8))\n",
    "\n",
    "# for i in range(5):\n",
    "#     for j in range(10):\n",
    "#         timestep = i * 10 + j\n",
    "#         if timestep < num_time_steps:\n",
    "#             axs[i, j].imshow(pred_WD[timestep], cmap='viridis')  # Adjust the colormap as needed\n",
    "#             axs[i, j].set_title(f\"Time Step {timestep + 1}\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54334328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
