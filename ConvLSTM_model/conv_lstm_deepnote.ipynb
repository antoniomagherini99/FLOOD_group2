{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"6745e274f5da440d8f75866d3a55b9d6","deepnote_cell_type":"markdown"},"source":["# ConvLSTM model"]},{"cell_type":"markdown","metadata":{"cell_id":"6e15ddc3ae0f40bda0d72baaa696cba1","deepnote_cell_type":"markdown"},"source":["Import libraries and modules."]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"317a1931967a493a820fae093f628cfa","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":777,"execution_start":1703258901929,"source_hash":"26b410bf"},"outputs":[],"source":["import torch\n","import os\n","# import imageio\n","\n","import numpy as np\n","import pandas as pd\n","# import matplotlib.pyplot as plt\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","\n","# from numba import jit, prange\n","\n","# from PIL import Image\n","# from sklearn.preprocessing import MinMaxScaler\n","# from torchsummary import summary\n","# from torch.utils.data import DataLoader\n","# from matplotlib.colors import TwoSlopeNorm\n","\n","from load_datasets import *\n","from ConvLSTM_pytorch import *"]},{"cell_type":"markdown","metadata":{"cell_id":"3b8c87dfefcc4dcb9099e17e1193a568","deepnote_cell_type":"markdown"},"source":["Check if GPU is available."]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"388661982cff45b2bff8175da7fa4243","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":8,"execution_start":1703258909998,"source_hash":"407af93f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"markdown","metadata":{"cell_id":"3a0f5b87a9e341119392b2536f71e1c7","deepnote_cell_type":"markdown"},"source":["The following paths access the main folder (i.e., _dataset_train_val_, _dataset1_ and so on). The path of the specific type of data (_DEM_, _VX_ and so on) is to be specified after."]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"26b1b73dd262445c884866e82c26f594","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":40,"execution_start":1703259005592,"source_hash":"5f5b5265"},"outputs":[],"source":["path_train = f'../dataset_train_val/' \n","path_test1 = f'../dataset1/'\n","path_test2 = f'../dataset2/'\n","path_test3 = f'../dataset3/'"]},{"cell_type":"markdown","metadata":{"cell_id":"4c107907144b43e5863002290b74aa57","deepnote_cell_type":"markdown"},"source":["The following lines create variables to more easily specify what we use the model for (i.e., train and validate, test with dataset 1 and so on) in the following functions."]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"6b7157af37c844b28bc5bf399b6be62b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":8,"execution_start":1703258911722,"source_hash":"2f7e85f"},"outputs":[],"source":["train_val = 'train_val'\n","test1 = 'test1'\n","test2 = 'test2'\n","test3 = 'test3'"]},{"cell_type":"markdown","metadata":{"cell_id":"9bdaef464b9b47cba6bbee3de33e2d32","deepnote_cell_type":"markdown"},"source":["Load data."]},{"cell_type":"markdown","metadata":{"cell_id":"5b334a37768c48e1b5fa83c00a44e9f9","deepnote_cell_type":"markdown"},"source":["Load DEM files."]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"e0c9b1b5f426489bb5e1009b5d3b2345","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":86552,"execution_start":1703262231238,"source_hash":"4ff12bd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n"]}],"source":["inputs, targets = load_all_boys('train_val')"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def encode_into_csv(inputs, targets, train_val_test):\n","    \"\"\"\n","    Due to the long run time of computing all inputs and targets, these will be encoded into a csv file\n","    to reduce the computatio duration\n","\n","    Input:\n","    inputs: torch.tensor of shape: samples x 3 x 64 x 64 which represents the inputs of the network\n","    targets: torch.tensor of shape: samples x time steps x 64 x 64 which represents the targets of the network\n","    train_val_test: str, differentiate between csv files\n","\n","    Outputs:\n","    None: But a csv file is create with a predetermined name\n","    \"\"\"\n","    # Flatten the tensors and concatenate them along the specified dimension\n","    flattened_tensor1 = torch.flatten(inputs, start_dim=0)\n","    flattened_tensor2 = torch.flatten(targets, start_dim=0)\n","\n","    # Convert the tensor to a pandas DataFrame\n","    df_inputs = pd.DataFrame(flattened_tensor1.numpy())\n","    df_targets = pd.DataFrame(flattened_tensor2.numpy())\n","\n","    # Save the DataFrame to a CSV file\n","    df_inputs.to_csv(train_val_test + '_in.csv', index=False)\n","\n","    # if train_val_test = 'train_val' targets file is too big to be loaded in GitHub\n","    # and it needs to be split into 4 different .csv files\n","    # n_tot = 63569920 total number of rows of targets (80x2x97x64x64)\n","    # n = n_tot/4 to split in 4 separate files\n","    n_tot = int(targets.size(0) * targets.size(1) * targets.size(2) * targets.size(3) * targets.size(4))\n","    n = int(n_tot / 4)\n","\n","    if train_val_test == 'train_val':\n","        df_targets[:n].to_csv(train_val_test + '_tar1.csv', index=False)\n","        df_targets[n:2*n].to_csv(train_val_test + '_tar2.csv', index=False)\n","        df_targets[2*n:3*n].to_csv(train_val_test + '_tar3.csv', index=False)\n","        df_targets[3*n:].to_csv(train_val_test + '_tar4.csv', index=False)\n","    else: \n","        df_targets.to_csv(train_val_test + '_tar.csv', index=False)\n","    return df_inputs, df_targets"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["def decode_from_csv(train_val_test):\n","    \"\"\"\n","    Due to the long run time of computing all inputs and targets, a csv file will be opened\n","    at the start of every notebook which represents the inputs and targets for a certain dataset\n","\n","    Input:\n","    train_val_test: str, identifies which dataset is being retrieved\n","\n","    Output:\n","    inputs: torch.Tensor which contains DEM, slope x and y for all files in a dataset\n","            Shape is samples x 3 x 64 x 64\n","    targets: torch.Tensor which contains water depth and discharge for all files in a dataset.\n","            Shape is samples x time steps x 2 x 64 x 64\n","    \"\"\"\n","    df_inputs = pd.read_csv(train_val_test + '_in.csv')\n","    \n","    # if train_val_test = 'train_val' targets file is too big to be loaded in GitHub\n","    # and it needs to be split into 4 different .csv files\n","    if train_val_test == 'train_val':\n","        df_targets1 = pd.read_csv(train_val_test + '_tar1.csv')\n","        df_targets2 = pd.read_csv(train_val_test + '_tar2.csv')\n","        df_targets3 = pd.read_csv(train_val_test + '_tar3.csv')\n","        df_targets4 = pd.read_csv(train_val_test + '_tar4.csv')\n","\n","        df_targets = pd.concat([df_targets1, df_targets2, \n","                                df_targets3, df_targets4], axis=0) \n","    else:\n","        df_targets = pd.read_csv(train_val_test + '_tar.csv')\n","\n","    # Convert the DataFrame to a PyTorch tensor\n","    restored_inputs = torch.tensor(df_inputs.values)\n","    restored_targets = torch.tensor(df_targets.values)\n","\n","    # Determine the original shapes of the tensors\n","    if 'train_val':\n","        samples = 80\n","    elif 'test1':\n","        samples = 21\n","    elif 'test2':\n","        samples = 20\n","    else:\n","        samples = 10\n","\n","    shape_tensor1 = (samples, 3, 64, 64)\n","    shape_tensor2 = (samples, 97, 2, 64, 64)\n","\n","    # Split the restored tensor into two tensors based on the original shapes\n","    inputs = torch.reshape(restored_inputs, shape_tensor1)\n","    targets = torch.reshape(restored_targets, shape_tensor2)\n","\n","    # Print the shapes of the restored tensors\n","    print(\"Restored inputs Shape:\", inputs.shape)\n","    print(\"Restored targets Shape:\", targets.shape)\n","    return inputs, targets"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["inps, targs = encode_into_csv(inputs, targets, train_val)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Restored inputs Shape: torch.Size([80, 3, 64, 64])\n","Restored targets Shape: torch.Size([80, 97, 2, 64, 64])\n"]}],"source":["inputs, targets = decode_from_csv(train_val)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["80\n"]}],"source":["# not needed anymore?\n","\n","# count = 0\n","# dir_path = path_train + 'DEM/' # Arbitrary choice as DEM, vx, vy and WD all have the same number of samples\n","# for path in os.listdir(dir_path):\n","#     if os.path.isfile(os.path.join(dir_path, path)):\n","#         count += 1\n","# inputs = torch.zeros((count, 3, 64, 64))\n","# targets = torch.zeros((count, 97, 2, 64, 64))\n","# print(count)"]},{"cell_type":"markdown","metadata":{},"source":["Test dataset 1."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inps1, targs1 = load_all_boys(test1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inps1, targs1 = encode_into_csv(inps1, targs1, test1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inps1, targs1 = decode_from_csv(test1)"]},{"cell_type":"markdown","metadata":{},"source":["Test dataset 2."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inps2, targs2 = load_all_boys(test2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inps2, targs2 = encode_into_csv(inps2, targs2, test2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inps1, targs1 = decode_from_csv(test2)"]},{"cell_type":"markdown","metadata":{},"source":["Test dataset 3."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inps3, targs3 = load_all_boys(test3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inps3, targs3 = encode_into_csv(inps3, targs3, test3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inps3, targs3 = decode_from_csv(test3)"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"4b953ff8b2a04095993ca3c1d8d4427b","deepnote_persisted_session":{"createdAt":"2023-12-22T15:19:57.116Z"},"kernelspec":{"display_name":"dsaie","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":0}
