{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb8027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib.colors import TwoSlopeNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c028673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_elevation_data(file_id):\n",
    "    \"\"\"\n",
    "    Processes elevation data from a DEM file.\n",
    "\n",
    "    Args:\n",
    "    file_id (str): Identifier of the DEM file to be processed.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: A tensor combining the original elevation data and its slope in x and y directions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the file path from the given file identifier\n",
    "    file_path = f'DEM_{file_id}.txt'\n",
    "\n",
    "    # Load the elevation data from the file\n",
    "    elevation_data = np.loadtxt(file_path)\n",
    "\n",
    "    # Reshape the elevation data into a 64x64 grid\n",
    "    elevation_grid = elevation_data[:, 2].reshape(64, 64)\n",
    "\n",
    "    # Convert the elevation grid to a PyTorch tensor\n",
    "    elevation_tensor = torch.tensor(elevation_grid)\n",
    "\n",
    "    # Compute the slope in the x and y directions\n",
    "    slope_x, slope_y = torch.gradient(elevation_tensor)\n",
    "\n",
    "    # Combine the elevation tensor with the slope tensors\n",
    "    elevation_slope_tensor = torch.stack((elevation_tensor, slope_x, slope_y), dim=0)\n",
    "\n",
    "    return elevation_slope_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca89b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_water_depth(file_id, time_step=0):\n",
    "    \"\"\"\n",
    "    Processes water depth data from a specific time step in a file.\n",
    "\n",
    "    Args:\n",
    "    file_id (str): Identifier of the water depth file to be processed.\n",
    "    time_step (int): Time step to extract from the file. Default is the first time step. Default is the first time step.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor or None: A 64x64 tensor representing water depth at the given time step, or None if the data is invalid.\n",
    "    \"\"\"\n",
    "    file_path = f'WD_{file_id}.txt'\n",
    "\n",
    "    # Read the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    try:\n",
    "        # Extract the specified row and convert string elements to floats\n",
    "        selected_row = lines[time_step].split()\n",
    "        depth_values = [float(val) for val in selected_row]\n",
    "\n",
    "        # Validate and reshape the data into a 64x64 tensor\n",
    "        if len(depth_values) == 64 * 64:\n",
    "            depth_tensor = torch.tensor(depth_values).view(64, 64)\n",
    "            return depth_tensor\n",
    "        else:\n",
    "            raise ValueError(f\"The number of elements in {file_path} at time step {time_step} doesn't match a 64x64 matrix.\")\n",
    "    except IndexError:\n",
    "        raise IndexError(f\"Time step {time_step} is out of range for the file {file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059d3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_tensors(tensors, file_number, titles):\n",
    "    \"\"\"\n",
    "    Plots a series of data tensors.\n",
    "\n",
    "    Args:\n",
    "    tensors (list of torch.Tensor): List of tensors to be plotted.\n",
    "    file_number (str): Identifier of the file corresponding to the data.\n",
    "    titles (list of str): Titles for each subplot corresponding to the tensors.\n",
    "    \"\"\"\n",
    "    num_tensors = len(tensors)\n",
    "    fig, axes = plt.subplots(1, num_tensors, figsize=(12, 5))\n",
    "\n",
    "    # Adjust for a single tensor case\n",
    "    if num_tensors == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, tensor, title in zip(axes, tensors, titles):\n",
    "        cmap = 'terrain' if title.startswith('Elevation') else 'coolwarm'\n",
    "        im = ax.imshow(tensor, cmap=cmap, origin='lower')\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plt.suptitle(f'Training Dataset Number {file_number}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcece26",
   "metadata": {},
   "source": [
    "## Plot an example of training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c29285",
   "metadata": {},
   "source": [
    "Each example corresponds to one full flood simulation, carried out assuming a dike breach flood with constant discharge of $50m^3/s$, starting in the bottom-left corner of the domain.\n",
    "The domain is a 64x64 grid where each tile/patch is $100m$ in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8957883",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "DEM_4.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m file_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m      2\u001b[0m WD_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[1;32m----> 3\u001b[0m elevation_slope_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_elevation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m water_depth_tensor \u001b[38;5;241m=\u001b[39m process_water_depth(file_id, time_step\u001b[38;5;241m=\u001b[39mWD_time_step)\n\u001b[0;32m      5\u001b[0m combined_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(elevation_slope_tensor) \u001b[38;5;241m+\u001b[39m [water_depth_tensor]\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mprocess_elevation_data\u001b[1;34m(file_id)\u001b[0m\n\u001b[0;32m     13\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEM_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Load the elevation data from the file\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m elevation_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Reshape the elevation data into a 64x64 grid\u001b[39;00m\n\u001b[0;32m     19\u001b[0m elevation_grid \u001b[38;5;241m=\u001b[39m elevation_data[:, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\npyio.py:1338\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1336\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1338\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1341\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\npyio.py:975\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    973\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 975\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: DEM_4.txt not found."
     ]
    }
   ],
   "source": [
    "file_id = 4\n",
    "WD_time_step = 12\n",
    "elevation_slope_tensor = process_elevation_data(file_id)\n",
    "water_depth_tensor = process_water_depth(file_id, time_step=WD_time_step)\n",
    "combined_tensors = list(elevation_slope_tensor) + [water_depth_tensor]\n",
    "\n",
    "# Splitting the title into two lines\n",
    "water_depth_title = f'Water Depth after\\n{WD_time_step*30} min'\n",
    "\n",
    "titles = ['Elevation', 'Slope X', 'Slope Y', water_depth_title]\n",
    "\n",
    "# Plot the data\n",
    "plot_dataset_tensors(combined_tensors, file_id, titles)\n",
    "# plt.savefig(r'C:\\Users\\carlo\\Desktop\\TU Delft\\DSAIE\\Flood_Project\\Inputs_Training', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8849837",
   "metadata": {},
   "source": [
    "## Create a movie for one example of Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e930f6c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the directory where you want to save the files\n",
    "output_dir = r'C:\\Users\\carlo\\Desktop\\TU Delft\\DSAIE\\Flood_Project\\WD_Training_Dataset_Movie'\n",
    "\n",
    "file_number = 4\n",
    "num_time_steps = 50  # Adjust this according to your number of time steps\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for WD_time_step in range(num_time_steps):\n",
    "    # Process data for each time step\n",
    "    elevation_slope_tensor = process_elevation_data(file_id)\n",
    "    water_depth_tensor = process_water_depth(file_id, time_step=WD_time_step)\n",
    "    combined_tensors = list(elevation_slope_tensor) + [water_depth_tensor]\n",
    "\n",
    "    # Update title\n",
    "    water_depth_title = f'Water Depth after\\n{WD_time_step*30} min'\n",
    "    titles = ['Elevation', 'Slope X', 'Slope Y', water_depth_title]\n",
    "\n",
    "    # Plot the data\n",
    "    plot_dataset_tensors(combined_tensors, file_id, titles)\n",
    "\n",
    "    # Save each plot as an image in the specified directory\n",
    "    filename = f'frame_{WD_time_step:03d}.png'\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    plt.savefig(filepath, dpi=500, bbox_inches='tight')\n",
    "    filenames.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, target_shape):\n",
    "    \"\"\"\n",
    "    Resize the image to the target shape using PIL.\n",
    "    \"\"\"\n",
    "    image_pil = Image.fromarray(image)\n",
    "    resized_image = image_pil.resize((target_shape[1], target_shape[0]), Image.ANTIALIAS)\n",
    "    return np.array(resized_image)\n",
    "\n",
    "movie_path = os.path.join(output_dir, 'WD_Training_Dataset_Movie.mp4')\n",
    "first_image = imageio.imread(filenames[1])\n",
    "image_shape = first_image.shape\n",
    "\n",
    "with imageio.get_writer(movie_path, fps=3) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        if image.shape != image_shape:\n",
    "            print(f\"Resizing image {filename} from {image.shape} to {image_shape}\")\n",
    "            image = resize_image(image, image_shape)\n",
    "        writer.append_data(image)\n",
    "\n",
    "# Optionally, remove the individual image files after creating the movie\n",
    "# for filename in filenames:\n",
    "#     os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07a865",
   "metadata": {},
   "source": [
    "## Creating the Training Dataset\n",
    "\n",
    "The training dataset is a list in which each element is a tuple with an input tensor and output tensor.\n",
    "\n",
    "Inputs:\n",
    "- digital elevation model (DEM)\n",
    "- slope in the x direction\n",
    "- slope in the y direction\n",
    "- water depth at a specific time step t<sub>0</sub>\n",
    "\n",
    "Outputs\n",
    "- water depth at a specific time step t<sub>0</sub>+t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the time t0 and t\n",
    "\n",
    "t0 = 10\n",
    "t = 50\n",
    "\n",
    "# Loop through file IDs from DEM_1 to DEM_80\n",
    "\n",
    "train_dataset = []\n",
    "\n",
    "for i in range(1, 81):  # Assuming file IDs are numbered from 1 to 80\n",
    "    file_id = i\n",
    "    \n",
    "    # Input Tensor (input_tensor.shape will be [4, 64, 64])\n",
    "    \n",
    "    elevation_slope_tensor = process_elevation_data(file_id)\n",
    "    water_depth_input_tensor = process_water_depth(file_id, time_step=t0) # Time Step is t0\n",
    "    # Add an extra dimension to make water_depth_tensor [1, 64, 64]\n",
    "    water_depth_input_tensor = torch.unsqueeze(water_depth_input_tensor, 0)\n",
    "    \n",
    "    # elevation_slope_tensor.shape --> [3, 64, 64]\n",
    "    # water_depth_tensor.shape --> [1,64, 64]\n",
    "\n",
    "    # Concatenate to create the input tensor\n",
    "    input_tensor = torch.cat((elevation_slope_tensor, water_depth_input_tensor), dim=0)\n",
    "    input_tensor = input_tensor.double()\n",
    "    \n",
    "    # Output Tensor (output_tensor.shape will be [1, 64, 64])\n",
    "    water_depth_output_tensor = process_water_depth(file_id, time_step=t0+t) # Time Step is now t0+t\n",
    "    # Add an extra dimension to make water_depth_tensor [1, 64, 64]\n",
    "    output_tensor = torch.unsqueeze(water_depth_output_tensor, 0)\n",
    "    output_tensor = output_tensor.double()\n",
    "    \n",
    "    # Create a tuple\n",
    "    train_dataset_sample = (input_tensor, output_tensor)\n",
    "    \n",
    "    # Append the sample to the train_dataset list\n",
    "    train_dataset.append(train_dataset_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae34258d",
   "metadata": {},
   "source": [
    "## Creating the Test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557dcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the time t0 and t\n",
    "\n",
    "t0 = 10\n",
    "t = 50\n",
    "\n",
    "# Loop through file IDs from DEM_500 to DEM_519\n",
    "\n",
    "test_dataset = []\n",
    "\n",
    "for i in range(500, 520):  # Assuming file IDs are numbered from 1 to 80\n",
    "    file_id = i\n",
    "    \n",
    "    # Input Tensor (input_tensor.shape will be [4, 64, 64])\n",
    "    \n",
    "    elevation_slope_tensor = process_elevation_data(file_id)\n",
    "    water_depth_input_tensor = process_water_depth(file_id, time_step=t0) # Time Step is t0\n",
    "    # Add an extra dimension to make water_depth_tensor [1, 64, 64]\n",
    "    water_depth_input_tensor = torch.unsqueeze(water_depth_input_tensor, 0)\n",
    "    \n",
    "    # elevation_slope_tensor.shape --> [3, 64, 64]\n",
    "    # water_depth_tensor.shape --> [1,64, 64]\n",
    "\n",
    "    # Concatenate to create the input tensor for this file ID\n",
    "    input_tensor = torch.cat((elevation_slope_tensor, water_depth_input_tensor), dim=0)\n",
    "    input_tensor = input_tensor.double()\n",
    "    \n",
    "    # Output Tensor (output_tensor.shape will be [1, 64, 64])\n",
    "    water_depth_output_tensor = process_water_depth(file_id, time_step=t0+t) # Time Step is now t0+t\n",
    "    # Add an extra dimension to make water_depth_tensor [1, 64, 64]\n",
    "    output_tensor = torch.unsqueeze(water_depth_output_tensor, 0)\n",
    "    output_tensor = output_tensor.double()\n",
    "    \n",
    "    # Create a tuple\n",
    "    test_dataset_sample = (input_tensor, output_tensor)\n",
    "    \n",
    "    # Append the sample to the train_dataset list\n",
    "    test_dataset.append(test_dataset_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ecfcf",
   "metadata": {},
   "source": [
    "## Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset, scaler_x, scaler_y):\n",
    "    min_x, max_x = scaler_x.data_min_[0], scaler_x.data_max_[0]\n",
    "    min_y, max_y = scaler_y.data_min_[0], scaler_y.data_max_[0]\n",
    "    normalized_dataset = []\n",
    "    for idx in range(len(dataset)):\n",
    "        x = dataset[idx][0]\n",
    "        y = dataset[idx][1]\n",
    "        norm_x = (x - min_x) / (max_x - min_x)\n",
    "        norm_y = (y - min_y) / (max_y - min_y)\n",
    "        normalized_dataset.append((norm_x, norm_y))\n",
    "    return normalized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the inputs and outputs using training dataset\n",
    "\n",
    "inputs, outputs = train_dataset[0]\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "for idx in range(len(train_dataset)):\n",
    "    scaler_x.partial_fit(train_dataset[idx][0].reshape(inputs.shape[0], -1).T.cpu())\n",
    "    scaler_y.partial_fit(train_dataset[idx][1].reshape(-1, 1).cpu())\n",
    "\n",
    "normalized_train_dataset = normalize_dataset(train_dataset, scaler_x, scaler_y)\n",
    "normalized_test_dataset = normalize_dataset(test_dataset, scaler_x, scaler_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abfb32",
   "metadata": {},
   "source": [
    "## Split dataset into train, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percnt = 0.8\n",
    "train_size = int(train_percnt * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(normalized_train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea823444",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create you own CNN model\n",
    "\n",
    "# Define the CNN architecture\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=4, n_classes=1, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 8))\n",
    "        self.down1 = (Down(8, 16))\n",
    "        self.down2 = (Down(16, 32))\n",
    "        self.down3 = (Down(32, 64))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(64, 128 // factor))\n",
    "        self.up1 = (Up(128, 64 // factor, bilinear))\n",
    "        self.up2 = (Up(64, 32 // factor, bilinear))\n",
    "        self.up3 = (Up(32, 16 // factor, bilinear))\n",
    "        self.up4 = (Up(16, 8, bilinear))\n",
    "        self.outc = (OutConv(8, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)\n",
    "\n",
    "# Instantiate the CNN\n",
    "model = UNet().to(device)  # Replace with your model and number of classes\n",
    "summary(model, input_size=(4, 64, 64))  # Replace with your input size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f583873",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd928f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train() # specifies that the model is in training mode\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        x, y = x.float().to(device), y.float().to(device)\n",
    "\n",
    "        # Model prediction\n",
    "        preds = model(x)\n",
    "\n",
    "        # MSE loss function\n",
    "        loss = nn.MSELoss()(preds, y)\n",
    "\n",
    "        losses.append(loss.cpu().detach())\n",
    "\n",
    "        # Backpropagate and update weights\n",
    "        loss.backward()   # compute the gradients using backpropagation\n",
    "        optimizer.step()  # update the weights with the optimizer\n",
    "        optimizer.zero_grad(set_to_none=True)   # reset the computed gradients\n",
    "\n",
    "    losses = np.array(losses).mean()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f427a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval() # specifies that the model is in evaluation mode\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[0]\n",
    "            y = batch[1]\n",
    "            x, y = x.float().to(device), y.float().to(device)\n",
    "\n",
    "            # Model prediction\n",
    "            preds = model(x)\n",
    "\n",
    "            # MSE loss function\n",
    "            loss = nn.MSELoss()(preds, y)\n",
    "            losses.append(loss.cpu().detach())\n",
    "\n",
    "    losses = np.array(losses).mean()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e13a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the optimizer to train the neural network via back-propagation\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training and validation dataloaders to \"feed\" data to the model in batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(normalized_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73171b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device=device)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    validation_loss = evaluation(model, val_loader, device=device)\n",
    "    validation_losses.append(validation_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}', f'Train Loss: {train_losses}', f'Validation Loss: {validation_losses}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c676b3",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86beb66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluation(model, test_loader, device=device)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b2037",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training')\n",
    "plt.plot(validation_losses, label='Validation')\n",
    "plt.yscale('log')\n",
    "plt.title('CNN training and validation losses')\n",
    "plt.xlabel('Epochs [-]')\n",
    "plt.ylabel('Loss [-]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941aa8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one sample\n",
    "data_id = 4\n",
    "\n",
    "x = normalized_test_dataset[data_id][0].unsqueeze(0)\n",
    "x = x.float().to(device)\n",
    "FAT = normalized_test_dataset[data_id][1]\n",
    "\n",
    "# predict the FAT\n",
    "pred_FAT = model(x).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEM = scaler_x.inverse_transform(x[0].reshape(4,-1).T.cpu())[:,0].reshape(64,64)\n",
    "real_FAT = scaler_y.inverse_transform(FAT.reshape(-1,1).cpu()).reshape(64,64)\n",
    "pred_FAT = scaler_y.inverse_transform(pred_FAT.reshape(-1,1).cpu()).reshape(64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdcd97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(17,5))\n",
    "\n",
    "diff_FAT = real_FAT - pred_FAT\n",
    "max_FAT = max(pred_FAT.max(), real_FAT.max())\n",
    "max_diff = max(diff_FAT.max(), -diff_FAT.min())\n",
    "\n",
    "axs[0].imshow(DEM.squeeze(), cmap='terrain', origin='lower')\n",
    "axs[1].imshow(real_FAT.squeeze(), vmin = 0, vmax=max_FAT, cmap='Blues_r', origin='lower')\n",
    "axs[2].imshow(pred_FAT.squeeze(), vmin = 0, vmax=max_FAT,cmap='Blues_r', origin='lower')\n",
    "axs[3].imshow(diff_FAT.squeeze(), vmin=-max_diff, vmax=max_diff, cmap='RdBu', origin='lower')\n",
    "\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = DEM.min(), vmax=DEM.max()),\n",
    "                            cmap='terrain'), fraction=0.05, shrink=0.9, ax=axs[0])\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_FAT),\n",
    "                            cmap='Blues_r'), fraction=0.05, shrink=0.9, ax=axs[1])\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_FAT),\n",
    "                            cmap='Blues_r'), fraction=0.05, shrink=0.9, ax=axs[2])\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=TwoSlopeNorm(vmin=-max_diff, vmax=max_diff, vcenter=0),\n",
    "                            cmap='RdBu'), fraction=0.05, shrink=0.9, ax=axs[3])\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "axs[0].set_title('DEM')\n",
    "axs[1].set_title('Real Water Depth (m)')\n",
    "axs[2].set_title('Predicted Water Depth (m)')\n",
    "axs[3].set_title('Difference (m)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb6535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
