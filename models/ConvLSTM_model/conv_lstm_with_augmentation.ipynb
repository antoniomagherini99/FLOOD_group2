{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Step ConvLSTM model\n",
    "\n",
    "This notebook contains a Single Step ConvLSTM model for flood predictions. \n",
    "It was developed for CEGM2003 DSAIE Crossover Module during 2023/2024 academic year at Delft University of Technology, Faculty of Civil Engineering and Geosciences.\n",
    "\n",
    "Credits to the original ConvLSTM model architecture go to [Andrea Palazzi](https://github.com/ndrplz) and [Davide Abati](https://github.com/DavideA).\n",
    "The source code is provided in the ([ConvLSTM_pytorch file](https://github.com/ndrplz/ConvLSTM_pytorch)), which is based on [this model](https://github.com/rogertrullo/pytorch_convlstm/blob/master/conv_lstm.py) implemented by [Roger Trullo](https://github.com/rogertrullo).\n",
    "\n",
    "For more information refer to the README in <code>models/ConvLSTM_model/ConvLSTM_pytorch/README.md</code>.\n",
    "\n",
    "Group: FLOOD2 ([GitHub group repository](https://github.com/antoniomagherini99/FLOOD_group2)). \n",
    "\n",
    "Authors of the notebook:\n",
    "- Lucas Terlinden-Ruhl \n",
    "\\\n",
    "(student number: 5863937, email: L.J.R.Terlinden-Ruhl@student.tudelft.nl)\n",
    "\n",
    "\n",
    "- Antonio Magherini \n",
    "\\\n",
    "(student number: 5838215, email: A.Magherini@student.tudelft.nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model implemented in this noteboook is a Single Step ConvLSTM: it combines a convolutional layer and the architecture of an LSTM model. It contains 48 layers as each layer is associated with a single predicted time step. The parameters were chosen based on an optimization process: different combinations of learning rate, hidden dimensions and so on were tested to get to this final version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to the root directory of the git\n",
    "\n",
    "%cd ..\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and modules\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable interactive widgets in Jupyter Notebook\n",
    "%matplotlib widget\n",
    "\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from models.ConvLSTM_model.ConvLSTM_pytorch.convlstm import ConvLSTM\n",
    "from models.ConvLSTM_model.train_eval import train_epoch_conv_lstm, evaluation_conv_lstm\n",
    "from pre_processing.encode_decode_csv import decode_from_csv\n",
    "from pre_processing.normalization import * \n",
    "from pre_processing.augmentation import * \n",
    "from post_processing.cool_animation import plot_animation\n",
    "from post_processing.plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is used to save the file path where to store the model. We suggest to use the following nomenclature for differentiate among different models:\n",
    "\n",
    "- <code>conv_lstm</code> specifies the type of the model (ConvLSTM in this case);\n",
    "- <code>32hid</code> specifies the number of hidden dimensions (32 in this case);\n",
    "- <code>48lay</code> specifies the number of layers (48 in this case);\n",
    "- <code>5ker</code> specifies the size of the kernel (5x5 in this case);\n",
    "- <code>augmentation</code> specifies that data augmentation is applied to the original dataset\n",
    "\n",
    "<span style=\"color: red;\">**Please note! In order not to overwrite the original models, when uncommenting the following lines the saved files must be renamed.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save path\n",
    "save_path = 'models/ConvLSTM_model/model_paths/conv_lstm_32hid_48lay_5ker_augmentation.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines create variables to more easily specify what we use the model for and therefore which dataset to load in the following functions.\n",
    "\n",
    "<code>train_val</code> specifies the model is used for training and validation, <code>test1</code> specifies the model is used for testing dataset 1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = 'train_val'\n",
    "test1 = 'test1'\n",
    "test2 = 'test2'\n",
    "test3 = 'test3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note**: \n",
    "\\\n",
    "inputs and targets in <code>train_val</code> are stored in the following way: \n",
    "\n",
    "- index 0 = 1, \n",
    "\n",
    "- index 1 = 10, \n",
    "\n",
    "- index 11 = 2, \n",
    "\n",
    "- index 12 = 20 \n",
    "\n",
    "- index 13 = 21, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation dataset\n",
    "train_dataset = decode_from_csv(train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply data augmentation with six different transformations: \n",
    "- three single fixed rotations of either 90°, 180°, and 270° (to keep the same dimensions of the dataset);\n",
    "- three horizontal flipping, with a specified probability of flipping <code>p_hflip=0.5</code> and the same rotations as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply data augmentation - horizontal flipping and rotation\n",
    "transformed_dataset = augmentation(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From FAT application - show input dataset\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10, 5))\n",
    "\n",
    "# specify which entry of the dataset to plot\n",
    "numb = 157\n",
    "inputs = transformed_dataset[numb][0][0]\n",
    "\n",
    "axs[0].imshow(inputs[0].cpu(), cmap='terrain', origin='lower')\n",
    "axs[0].set_title('DEM')\n",
    "\n",
    "axs[1].imshow(inputs[1].cpu(), cmap='RdBu', origin='lower')\n",
    "axs[1].set_title('Slope X')\n",
    "\n",
    "axs[2].imshow(inputs[2].cpu(), cmap='RdBu', origin='lower')\n",
    "axs[2].set_title('Slope Y')\n",
    "\n",
    "non_zero_indices = torch.nonzero(inputs[3].cpu())\n",
    "non_zero_row, non_zero_col = non_zero_indices[0][0].item(), non_zero_indices[0][1].item()\n",
    "axs[3].imshow(inputs[3].cpu(), cmap='binary', origin='lower')\n",
    "axs[3].set_title('Breach Location')\n",
    "axs[3].scatter(non_zero_col, non_zero_row, color='k', marker='x', s=100,\n",
    "                clip_on = False, clip_box = plt.gca().transData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we fix the seed for the random split of the training and validation dataset. \n",
    "\n",
    "This is done for keeping consistency within the [Multi Step ConvLSTM model](https://github.com/antoniomagherini99/FLOOD_group2/blob/main/models/ConvLSTM_model/test_augmentation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "random_gen = torch.Generator().manual_seed(42) \n",
    "\n",
    "# Split dataset into train and validation\n",
    "train_percnt = 0.8\n",
    "train_size = int(train_percnt * len(transformed_dataset))\n",
    "val_size = len(transformed_dataset) - train_size\n",
    "train_set, val_set = random_split(transformed_dataset, [train_size, val_size], random_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the inputs and outputs using training dataset\n",
    "scaler_x, scaler_y = scaler(train_set)\n",
    "\n",
    "normalized_train_dataset = normalize_dataset(train_set, scaler_x, scaler_y, train_val)\n",
    "normalized_val_dataset = normalize_dataset(val_set, scaler_x, scaler_y, train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we save <code>scaler_x</code> and <code>scaler_y</code> for which the random seed was fixed and the data augmentation was applied. This is done for reusing the same scalers in the testing notebook. \n",
    "\n",
    "As the scalers need to be saved only the first time the notebook is run, the following lines are commented. Every time the random seed of the scaler is changed and/or the augmentation function is changed (different transformation, different amount of transformations), the scalers need to be saved again. \n",
    "\n",
    "<span style=\"color: red;\">**Please note: in order not to overwrite the original scalers, when uncommenting the following lines the saved files must be renamed.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## save scalers for use in seperate notebooks on testing\n",
    "# joblib.dump(scaler_x, 'models/ConvLSTM_model/scalers/scaler_x.joblib')\n",
    "# joblib.dump(scaler_y, 'models/ConvLSTM_model/scalers/scaler_y.joblib');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a specific hidden dimension <code>hidden_dim</code> and input dimension <code>input_dim</code>, the first layer receives the <code>hidden_dim</code> as hidden dimension of previous time step and <code>input_dim</code> as input dimension of the current time step and outputs <code>hidden_dim</code> to the next time step and next layer at current time step. Therefore, the next layer receives <code>hidden_dim</code> as both hidden dimension of previous time step and input dimension of current time step and outputs <code>hidden_dim</code> for both next time step and next layer and so on.\n",
    "\n",
    "The model has only one convolutional layer located before the gates. This layer outputs a <code>4*hidden_dim</code> to each gate because there are 4 gates (input, forget, tanh activation and output). \n",
    "\n",
    "As this is a Single Step predicting model, it needs <code>num_layers=48</code> for the first two datasets (<code>num_layers=120</code> for the third). It doesn't provide the hidden state to the next time step but only to next layer, which effectively represents the next time step. It is autoregressive (there is a relation in time) but layers are different per each time step, therefore also parameters are different leading to an increase of the total amount of parameters needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Model\n",
    "model = ConvLSTM(input_dim = normalized_train_dataset[0][0].shape[1], \n",
    "                 output_dim = normalized_train_dataset[0][1].shape[1], \n",
    "                 hidden_dim = 4, kernel_size = (3, 3), num_layers = 48, \n",
    "                 batch_first=True, bias=True, return_all_layers = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of parameters and model size\n",
    "num_parameters = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {num_parameters}\")\n",
    "model_size_MB = num_parameters * 4 / (1024 ** 2)  # Assuming float32 precision\n",
    "print(f\"Model size: {model_size_MB:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "learning_rate = 0.0001\n",
    "batch_size = 32\n",
    "num_epochs = 3500\n",
    "\n",
    "# Create the optimizer to train the neural network via back-propagation\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the scheduler for decreasing the learning rate every specified amount of epochs with a factor = gamma\n",
    "scheduler = StepLR(optimizer, step_size = 50, gamma = 0.8)\n",
    "\n",
    "# Create the training and validation dataloaders to feed data to the model in batches\n",
    "train_loader = DataLoader(normalized_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(normalized_val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can now be trained. The loss used in this notebook is the Mean Squared Error (<code>'MSE'</code>) but Mean Absolute Error can also be used (<code>'MAE'</code>). \n",
    "\n",
    "To use the Mean Absolute Error it is enough to set <code>loss_f='MAE'</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "count = 0\n",
    "\n",
    "# specify loss function\n",
    "loss_f = 'MSE'\n",
    "\n",
    "# train and validate the model\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Model training\n",
    "    train_loss = train_epoch_conv_lstm(model, train_loader, optimizer, device, loss_f)\n",
    "\n",
    "    # Model validation\n",
    "    val_loss = evaluation_conv_lstm(model, val_loader, device, loss_f)\n",
    "\n",
    "    if epoch == 1:\n",
    "        best_loss = val_loss\n",
    "\n",
    "    # save best model\n",
    "    if val_loss<=best_loss:\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        count = 0\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    count += 1\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        print(f\"Epoch: {epoch} \" +\n",
    "              f\"\\t Training loss: {train_loss: .2e} \" + \n",
    "              f\"\\t Validation loss: {val_loss: .2e} \" +\n",
    "              f\"\\t Best validation loss: {best_loss: .2e}\")\n",
    "        print(f'Current learning rate: {scheduler.get_last_lr()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "model = copy.deepcopy(best_model)\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show loss evolution with epochs\n",
    "plot_losses(train_losses, val_losses, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, <code>save=True</code> has to be set in order to save the animated gif otherwise it will just be displayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot animated gif showing the flood propagation in time\n",
    "plot_animation(30, normalized_val_dataset, model, train_val,\n",
    "               scaler_x, scaler_y, device = device, save = False, loss_f=loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot samples, losses and recall based on increasing loss\n",
    "plot_sorted(normalized_val_dataset, model, train_val, scaler_x, scaler_y, device, loss_f=loss_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
