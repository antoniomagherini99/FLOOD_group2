{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (convlstm.py, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\ProgramData\\Anaconda3\\envs\\dsaie\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3548\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 21\u001b[1;36m\n\u001b[1;33m    from ConvLSTM_pytorch.convlstm import ConvLSTM\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Users\\anton\\OneDrive\\Desktop\\TU Delft\\Q6\\Data Science and Artificial Intelligence for Engineers\\FLOOD_group2\\models\\ConvLSTM_model\\ConvLSTM_pytorch\\convlstm.py:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    <<<<<<< HEAD:ConvLSTM_model/ConvLSTM_pytorch/convlstm.py\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# Enable interactive widgets in Jupyter Notebook\n",
    "%matplotlib widget\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from numba import jit, prange\n",
    "# from PIL import Image\n",
    "import importlib  \n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "from ConvLSTM_pytorch.convlstm import ConvLSTM\n",
    "from encode_decode_csv import decode_from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines create variables to more easily specify what we use the model for (i.e., train and validate, test with dataset 1 and so on) in the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = 'train_val'\n",
    "test1 = 'test1'\n",
    "test2 = 'test2'\n",
    "test3 = 'test3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note**: \n",
    "\\\n",
    "inputs and targets in <code>train_val</code> are stored not in the original manner. \n",
    "\n",
    "index 0 = 1, index 1 = 10, index 11 = 2, index 12 = 20 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation dataset\n",
    "inputs, targets = decode_from_csv(train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset 1\n",
    "inps1, targs1 = decode_from_csv(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset 2\n",
    "inps2, targs2 = decode_from_csv(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset 3\n",
    "inps3, targs3 = decode_from_csv(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From FAT application\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10, 5))\n",
    "\n",
    "# specify which entry of the dataset to plot\n",
    "numb = 0\n",
    "\n",
    "axs[0].imshow(inputs[numb][0].cpu(), cmap='terrain', origin='lower')\n",
    "axs[0].set_title('DEM')\n",
    "\n",
    "axs[1].imshow(inputs[numb][1].cpu(), cmap='RdBu', origin='lower')\n",
    "axs[1].set_title('Slope X')\n",
    "\n",
    "axs[2].imshow(inputs[numb][2].cpu(), cmap='RdBu', origin='lower')\n",
    "axs[2].set_title('Slope Y')\n",
    "\n",
    "# kept it simple and did not include this in the inputs, but for generalization, this should be an input\n",
    "# Discharge is just zeros, probably redundant\n",
    "axs[3].imshow(targets[numb][0][0].cpu(), cmap='Set1', origin='lower')\n",
    "axs[3].set_title('Water Depth time step 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change following independent variables #\n",
    "target_tensor = targets\n",
    "input_tensor = inputs\n",
    "title_anim = train_val\n",
    "sample = 2\n",
    "feature1 = 0\n",
    "feature2 = 1\n",
    "# -------------------------------------- #\n",
    "\n",
    "feature_dic = {\n",
    "    0: 'Water Depth',\n",
    "    1: 'Discharge per meter width'\n",
    "}\n",
    "\n",
    "feature_dic_units = {\n",
    "    0: r'$m$',\n",
    "    1: r'$m^2 s^{-1}$'\n",
    "}\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 4))\n",
    "fig.subplots_adjust(wspace=0.5)  # Adjust the width space between subplots\n",
    "\n",
    "# Subplot 1\n",
    "div1 = make_axes_locatable(ax1)\n",
    "cax1 = div1.append_axes('right', '5%', '5%')\n",
    "\n",
    "static_tensor = input_tensor[sample, 0] # index 0 refers to elevation\n",
    "im1 = ax1.imshow(static_tensor, origin='lower')\n",
    "cb1 = fig.colorbar(im1, cax=cax1)\n",
    "cb1.set_label(r'$m$')\n",
    "ax1.set_title('Elevation')\n",
    "\n",
    "# Subplot 2\n",
    "div2 = make_axes_locatable(ax2)\n",
    "cax2 = div2.append_axes('right', '5%', '5%')\n",
    "\n",
    "animated_tensor1 = target_tensor[sample, feature1]\n",
    "im2 = ax2.imshow(animated_tensor1[0], origin='lower')\n",
    "cb2 = fig.colorbar(im2, cax=cax2)\n",
    "cb2.set_label(f'{feature_dic_units[feature1]}')\n",
    "tx2 = ax2.set_title(f'Frame 0: {feature_dic[feature1]}')\n",
    "\n",
    "# Subplot 3\n",
    "div3 = make_axes_locatable(ax3)\n",
    "cax3 = div3.append_axes('right', '5%', '5%')\n",
    "\n",
    "animated_tensor2 = target_tensor[sample, feature2]\n",
    "im3 = ax3.imshow(animated_tensor2[0], origin='lower')\n",
    "cb3 = fig.colorbar(im3, cax=cax3)\n",
    "cb3.set_label(f'{feature_dic_units[feature2]}')\n",
    "tx3 = ax3.set_title(f'Frame 0: {feature_dic[feature2]}')\n",
    "\n",
    "main_title = fig.suptitle(title_anim + f' targets for sample: {sample}', fontsize=16)\n",
    "\n",
    "def animate(i):\n",
    "    # Subplot 2\n",
    "    arr1 = animated_tensor1[i]\n",
    "    max_val1 = arr1.max()\n",
    "    min_val1 = arr1.min()\n",
    "    im2.set_data(arr1)\n",
    "    im2.set_clim(min_val1, max_val1)\n",
    "    tx2.set_text(f'Frame {i}: {feature_dic[feature1]}')\n",
    "\n",
    "    # Subplot 3\n",
    "    arr2 = animated_tensor2[i]\n",
    "    max_val2 = arr2.max()\n",
    "    min_val2 = arr2.min()\n",
    "    im3.set_data(arr2)\n",
    "    im3.set_clim(min_val2, max_val2)\n",
    "    tx3.set_text(f'Frame {i}: {feature_dic[feature2]}')\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=target_tensor.shape[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the animation as a gif\n",
    "# ani.save('example.gif', writer='Pillow', fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_in_or_tar(in_or_tar, scaler_x, scaler_y):\n",
    "    if len(in_or_tar.shape) == 4: # inputs, only use scalar x  \n",
    "        min_var, max_var = scaler_x.data_min_[0], scaler_x.data_max_[0]\n",
    "    elif len(in_or_tar.shape) == 5: # targets, only use scalar y\n",
    "        min_var, max_var = scaler_y.data_min_[0], scaler_y.data_max_[0]\n",
    "    else:\n",
    "        raise Exception(\"Something is wrong with encoder/decoder\")\n",
    "    normalized_in_or_out = []\n",
    "    for idx in range(in_or_tar.shape[0]):\n",
    "        var = in_or_tar[idx]\n",
    "        norm_var = (var - min_var) / (max_var - min_var)\n",
    "        normalized_in_or_out.append(norm_var)\n",
    "    return torch.stack(normalized_in_or_out, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the inputs and targets using training dataset\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "for idx in range(inputs.shape[0]):\n",
    "    scaler_x.partial_fit(inputs[idx].reshape(inputs.shape[1], -1).T.cpu())\n",
    "    scaler_y.partial_fit(targets[idx].reshape(targets.shape[1], -1).T.cpu())\n",
    "\n",
    "normalized_inputs = normalize_in_or_tar(inputs, scaler_x, scaler_y)\n",
    "normalized_inputs = normalized_inputs.unsqueeze(2) # new shape to make the model understand there is only one timestep\n",
    "normalized_targets = normalize_in_or_tar(targets, scaler_x, scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset to split randomly for train and val\n",
    "# place timesteps in index position 1, features position 2, I think this is what convlstm is expecting\n",
    "my_dataset = TensorDataset(normalized_inputs.permute(0, 2, 1, 3, 4), normalized_targets.permute(0, 2, 1, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset[79][0].shape # first position is the samples, second decides between inputs or targets, notice new shape of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and validation\n",
    "train_percnt = 0.8\n",
    "train_size = int(train_percnt * inputs.shape[0])\n",
    "val_size = inputs.shape[0] - train_size\n",
    "train_dataset, val_dataset = random_split(my_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, check, not sure num_layers is the expected amount of outputs\n",
    "model = ConvLSTM(input_dim = inputs.shape[1], hidden_dim = 2, kernel_size = (3, 3), num_layers = 2,\n",
    "         batch_first=True, bias=False, return_all_layers = True).to(device)\n",
    "# return all layers has to be true to obtain all the outputs I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device='cpu'):\n",
    "    model.float()\n",
    "    model.train()  # specifies that the model is in training mode\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[0].float().to(device)\n",
    "        y = batch[1].float().to(device)\n",
    "\n",
    "        # Initialize a variable to store previous output\n",
    "        prev_output = None\n",
    "\n",
    "        # Model prediction for each time step\n",
    "        for t in range(y.size(1)):\n",
    "            if prev_output is not None:\n",
    "                #x_t = torch.cat([x, prev_output], dim=1)\n",
    "                x_t = prev_output # use previous output as current input\n",
    "            else:\n",
    "                x_t = x.to(torch.float32)  # For the first time step\n",
    "            print(x_t)\n",
    "            # Model forward pass\n",
    "            layer_outputs, _ = model(x_t) # hidden state not implemented in py file can't use as input\n",
    "\n",
    "            # Choose the output from the desired layer (e.g., last layer)\n",
    "            desired_layer_output = layer_outputs[-1]\n",
    "\n",
    "            # MSE loss function\n",
    "            loss = nn.MSELoss()(desired_layer_output, y[:, t, :, :, :].unsqueeze(1))\n",
    "\n",
    "            losses.append(loss.cpu().detach())\n",
    "\n",
    "            # Use the current output as the input for the next time step\n",
    "            prev_output = desired_layer_output.detach()\n",
    "\n",
    "            # Backpropagate and update weights for every time step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    losses = np.array(losses).mean()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once train_epoch works change evaluation accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, loader, device='cpu'):\n",
    "    model.eval() # specifies that the model is in evaluation mode\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "\n",
    "            \n",
    "\n",
    "            # Model prediction for each time step\n",
    "            for t in range(y.size(1)):\n",
    "                None\n",
    "    losses = np.array(losses).mean()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 4 # Only have 64 and 16 samples for training and validation, I think should be kept small\n",
    "num_epochs = 10\n",
    "\n",
    "# Create the optimizer to train the neural network via back-propagation\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training and validation dataloaders to \"feed\" data to the model in batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    # Model training\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device=device)\n",
    "\n",
    "    # Model validation\n",
    "    val_loss = evaluation(model, val_loader, device=device)\n",
    "\n",
    "    if epoch == 1:\n",
    "        best_loss = val_loss\n",
    "    \n",
    "    if val_loss<=best_loss:\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        print(\"epoch:\",epoch, \"\\t training loss:\", np.round(train_loss,4),\n",
    "                            \"\\t validation loss:\", np.round(val_loss,4))\n",
    "        \n",
    "model = copy.deepcopy(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
