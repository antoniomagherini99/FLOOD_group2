{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84eae4c7",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb8027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "from load_datasets import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558009b",
   "metadata": {},
   "source": [
    "The following paths access the main folder (i.e., _dataset_train_val_, _dataset1_ and so on). The path of the specific type of data (_DEM_, _VX_ and so on) is to be specified after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee7aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = f'./dataset_train_val/' \n",
    "path_test1 = f'./dataset1/'\n",
    "path_test2 = f'./dataset2/'\n",
    "path_test3 = f'./dataset3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd005fa",
   "metadata": {},
   "source": [
    "The following lines create variables to more easily specify what we use the model for (i.e., train and validate, test with dataset 1 and so on) in the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = 'train_val'\n",
    "test1 = 'test1'\n",
    "test2 = 'test2'\n",
    "test3 = 'test3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcece26",
   "metadata": {},
   "source": [
    "## Plot an example of training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c29285",
   "metadata": {},
   "source": [
    "Each example corresponds to one full flood simulation, carried out assuming a dike breach flood with constant discharge of $50m^3/s$, starting in the bottom-left corner of the domain.\n",
    "The domain is a 64x64 grid where each tile/patch is $100m$ in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8957883",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = 4\n",
    "WD_time_step = 12\n",
    "elevation_slope_tensor = process_elevation_data(file_id)\n",
    "water_depth_tensor = process_water_depth(file_id, time_step=WD_time_step)\n",
    "combined_tensors = list(elevation_slope_tensor) + [water_depth_tensor]\n",
    "\n",
    "# Splitting the title into two lines\n",
    "water_depth_title = f'Water Depth after\\n{WD_time_step*30} min'\n",
    "\n",
    "titles = ['Elevation', 'Slope X', 'Slope Y', water_depth_title]\n",
    "\n",
    "# Plot the data\n",
    "plot_dataset_tensors(combined_tensors, file_id, titles)\n",
    "# plt.savefig(r'C:\\Users\\carlo\\Desktop\\TU Delft\\DSAIE\\Flood_Project\\Inputs_Training', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8849837",
   "metadata": {},
   "source": [
    "## Create a movie for one example of Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e930f6c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the directory where you want to save the files\n",
    "output_dir = r'C:\\Users\\carlo\\Desktop\\TU Delft\\DSAIE\\Flood_Project\\WD_Training_Dataset_Movie'\n",
    "\n",
    "file_number = 4\n",
    "num_time_steps = 50  # Adjust this according to your number of time steps\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for WD_time_step in range(num_time_steps):\n",
    "    # Process data for each time step\n",
    "    elevation_slope_tensor = process_elevation_data(file_id)\n",
    "    water_depth_tensor = process_water_depth(file_id, time_step=WD_time_step)\n",
    "    combined_tensors = list(elevation_slope_tensor) + [water_depth_tensor]\n",
    "\n",
    "    # Update title\n",
    "    water_depth_title = f'Water Depth after\\n{WD_time_step*30} min'\n",
    "    titles = ['Elevation', 'Slope X', 'Slope Y', water_depth_title]\n",
    "\n",
    "    # Plot the data\n",
    "    plot_dataset_tensors(combined_tensors, file_id, titles)\n",
    "\n",
    "    # Save each plot as an image in the specified directory\n",
    "    filename = f'frame_{WD_time_step:03d}.png'\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    plt.savefig(filepath, dpi=500, bbox_inches='tight')\n",
    "    filenames.append(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07a865",
   "metadata": {},
   "source": [
    "## Creating the Training Dataset\n",
    "\n",
    "The training dataset is a list in which each element is a tuple with an input tensor and output tensor.\n",
    "\n",
    "Inputs:\n",
    "- digital elevation model (DEM)\n",
    "- slope in the x direction\n",
    "- slope in the y direction\n",
    "- water depth at a specific time step t<sub>0</sub>\n",
    "\n",
    "Outputs\n",
    "- water depth at a specific time step t<sub>0</sub>+t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the time t0 and t\n",
    "\n",
    "t0 = 10\n",
    "t = 50\n",
    "\n",
    "# Loop through file IDs from DEM_1 to DEM_80\n",
    "\n",
    "train_dataset = []\n",
    "\n",
    "for i in range(1, 81):  # Assuming file IDs are numbered from 1 to 80\n",
    "    file_id = i\n",
    "    \n",
    "    # Input Tensor (input_tensor.shape will be [4, 64, 64])\n",
    "    \n",
    "    elevation_slope_tensor = process_elevation_data(file_id)\n",
    "    water_depth_input_tensor = process_water_depth(file_id, time_step=t0) # Time Step is t0\n",
    "    # Add an extra dimension to make water_depth_tensor [1, 64, 64]\n",
    "    water_depth_input_tensor = torch.unsqueeze(water_depth_input_tensor, 0)\n",
    "    \n",
    "    # elevation_slope_tensor.shape --> [3, 64, 64]\n",
    "    # water_depth_tensor.shape --> [1,64, 64]\n",
    "\n",
    "    # Concatenate to create the input tensor\n",
    "    input_tensor = torch.cat((elevation_slope_tensor, water_depth_input_tensor), dim=0)\n",
    "    input_tensor = input_tensor.double()\n",
    "    \n",
    "    # Output Tensor (output_tensor.shape will be [1, 64, 64])\n",
    "    water_depth_output_tensor = process_water_depth(file_id, time_step=t0+t) # Time Step is now t0+t\n",
    "    # Add an extra dimension to make water_depth_tensor [1, 64, 64]\n",
    "    output_tensor = torch.unsqueeze(water_depth_output_tensor, 0)\n",
    "    output_tensor = output_tensor.double()\n",
    "    \n",
    "    # Create a tuple\n",
    "    train_dataset_sample = (input_tensor, output_tensor)\n",
    "    \n",
    "    # Append the sample to the train_dataset list\n",
    "    train_dataset.append(train_dataset_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae34258d",
   "metadata": {},
   "source": [
    "## Creating the Test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557dcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the time t0 and t\n",
    "\n",
    "t0 = 10\n",
    "t = 50\n",
    "\n",
    "# Loop through file IDs from DEM_500 to DEM_519\n",
    "\n",
    "test_dataset = []\n",
    "\n",
    "for i in range(500, 520):  # Assuming file IDs are numbered from 1 to 80\n",
    "    file_id = i\n",
    "    \n",
    "    # Input Tensor (input_tensor.shape will be [4, 64, 64])\n",
    "    \n",
    "    elevation_slope_tensor = process_elevation_data(file_id)\n",
    "    water_depth_input_tensor = process_water_depth(file_id, time_step=t0) # Time Step is t0\n",
    "    # Add an extra dimension to make water_depth_tensor [1, 64, 64]\n",
    "    water_depth_input_tensor = torch.unsqueeze(water_depth_input_tensor, 0)\n",
    "    \n",
    "    # elevation_slope_tensor.shape --> [3, 64, 64]\n",
    "    # water_depth_tensor.shape --> [1,64, 64]\n",
    "\n",
    "    # Concatenate to create the input tensor for this file ID\n",
    "    input_tensor = torch.cat((elevation_slope_tensor, water_depth_input_tensor), dim=0)\n",
    "    input_tensor = input_tensor.double()\n",
    "    \n",
    "    # Output Tensor (output_tensor.shape will be [1, 64, 64])\n",
    "    water_depth_output_tensor = process_water_depth(file_id, time_step=t0+t) # Time Step is now t0+t\n",
    "    # Add an extra dimension to make water_depth_tensor [1, 64, 64]\n",
    "    output_tensor = torch.unsqueeze(water_depth_output_tensor, 0)\n",
    "    output_tensor = output_tensor.double()\n",
    "    \n",
    "    # Create a tuple\n",
    "    test_dataset_sample = (input_tensor, output_tensor)\n",
    "    \n",
    "    # Append the sample to the train_dataset list\n",
    "    test_dataset.append(test_dataset_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ecfcf",
   "metadata": {},
   "source": [
    "## Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset, scaler_x, scaler_y):\n",
    "    min_x, max_x = scaler_x.data_min_[0], scaler_x.data_max_[0]\n",
    "    min_y, max_y = scaler_y.data_min_[0], scaler_y.data_max_[0]\n",
    "    normalized_dataset = []\n",
    "    for idx in range(len(dataset)):\n",
    "        x = dataset[idx][0]\n",
    "        y = dataset[idx][1]\n",
    "        norm_x = (x - min_x) / (max_x - min_x)\n",
    "        norm_y = (y - min_y) / (max_y - min_y)\n",
    "        normalized_dataset.append((norm_x, norm_y))\n",
    "    return normalized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the inputs and outputs using training dataset\n",
    "\n",
    "inputs, outputs = train_dataset[0]\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "for idx in range(len(train_dataset)):\n",
    "    scaler_x.partial_fit(train_dataset[idx][0].reshape(inputs.shape[0], -1).T.cpu())\n",
    "    scaler_y.partial_fit(train_dataset[idx][1].reshape(-1, 1).cpu())\n",
    "\n",
    "normalized_train_dataset = normalize_dataset(train_dataset, scaler_x, scaler_y)\n",
    "normalized_test_dataset = normalize_dataset(test_dataset, scaler_x, scaler_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abfb32",
   "metadata": {},
   "source": [
    "## Split dataset into train, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percnt = 0.8\n",
    "train_size = int(train_percnt * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(normalized_train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea823444",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create you own CNN model\n",
    "\n",
    "# Define the CNN architecture\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=4, n_classes=1, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 8))\n",
    "        self.down1 = (Down(8, 16))\n",
    "        self.down2 = (Down(16, 32))\n",
    "        self.down3 = (Down(32, 64))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(64, 128 // factor))\n",
    "        self.up1 = (Up(128, 64 // factor, bilinear))\n",
    "        self.up2 = (Up(64, 32 // factor, bilinear))\n",
    "        self.up3 = (Up(32, 16 // factor, bilinear))\n",
    "        self.up4 = (Up(16, 8, bilinear))\n",
    "        self.outc = (OutConv(8, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)\n",
    "\n",
    "# Instantiate the CNN\n",
    "model = UNet().to(device)  # Replace with your model and number of classes\n",
    "summary(model, input_size=(4, 64, 64))  # Replace with your input size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f583873",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd928f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train() # specifies that the model is in training mode\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        x, y = x.float().to(device), y.float().to(device)\n",
    "\n",
    "        # Model prediction\n",
    "        preds = model(x)\n",
    "\n",
    "        # MSE loss function\n",
    "        loss = nn.MSELoss()(preds, y)\n",
    "\n",
    "        losses.append(loss.cpu().detach())\n",
    "\n",
    "        # Backpropagate and update weights\n",
    "        loss.backward()   # compute the gradients using backpropagation\n",
    "        optimizer.step()  # update the weights with the optimizer\n",
    "        optimizer.zero_grad(set_to_none=True)   # reset the computed gradients\n",
    "\n",
    "    losses = np.array(losses).mean()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f427a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval() # specifies that the model is in evaluation mode\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch[0]\n",
    "            y = batch[1]\n",
    "            x, y = x.float().to(device), y.float().to(device)\n",
    "\n",
    "            # Model prediction\n",
    "            preds = model(x)\n",
    "\n",
    "            # MSE loss function\n",
    "            loss = nn.MSELoss()(preds, y)\n",
    "            losses.append(loss.cpu().detach())\n",
    "\n",
    "    losses = np.array(losses).mean()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e13a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the optimizer to train the neural network via back-propagation\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training and validation dataloaders to \"feed\" data to the model in batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(normalized_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73171b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device=device)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    validation_loss = evaluation(model, val_loader, device=device)\n",
    "    validation_losses.append(validation_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}', f'Train Loss: {train_losses}', f'Validation Loss: {validation_losses}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c676b3",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86beb66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluation(model, test_loader, device=device)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b2037",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training')\n",
    "plt.plot(validation_losses, label='Validation')\n",
    "plt.yscale('log')\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941aa8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one sample\n",
    "data_id = 4\n",
    "\n",
    "x = normalized_test_dataset[data_id][0].unsqueeze(0)\n",
    "x = x.float().to(device)\n",
    "FAT = normalized_test_dataset[data_id][1]\n",
    "\n",
    "# predict the FAT\n",
    "pred_FAT = model(x).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEM = scaler_x.inverse_transform(x[0].reshape(4,-1).T.cpu())[:,0].reshape(64,64)\n",
    "real_FAT = scaler_y.inverse_transform(FAT.reshape(-1,1).cpu()).reshape(64,64)\n",
    "pred_FAT = scaler_y.inverse_transform(pred_FAT.reshape(-1,1).cpu()).reshape(64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdcd97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(17,5))\n",
    "\n",
    "diff_FAT = real_FAT - pred_FAT\n",
    "max_FAT = max(pred_FAT.max(), real_FAT.max())\n",
    "max_diff = max(diff_FAT.max(), -diff_FAT.min())\n",
    "\n",
    "axs[0].imshow(DEM.squeeze(), cmap='terrain', origin='lower')\n",
    "axs[1].imshow(real_FAT.squeeze(), vmin = 0, vmax=max_FAT, cmap='Blues_r', origin='lower')\n",
    "axs[2].imshow(pred_FAT.squeeze(), vmin = 0, vmax=max_FAT,cmap='Blues_r', origin='lower')\n",
    "axs[3].imshow(diff_FAT.squeeze(), vmin=-max_diff, vmax=max_diff, cmap='RdBu', origin='lower')\n",
    "\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = DEM.min(), vmax=DEM.max()),\n",
    "                            cmap='terrain'), fraction=0.05, shrink=0.9, ax=axs[0])\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_FAT),\n",
    "                            cmap='Blues_r'), fraction=0.05, shrink=0.9, ax=axs[1])\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=plt.Normalize(vmin = 0, vmax=max_FAT),\n",
    "                            cmap='Blues_r'), fraction=0.05, shrink=0.9, ax=axs[2])\n",
    "plt.colorbar(plt.cm.ScalarMappable(norm=TwoSlopeNorm(vmin=-max_diff, vmax=max_diff, vcenter=0),\n",
    "                            cmap='RdBu'), fraction=0.05, shrink=0.9, ax=axs[3])\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "axs[0].set_title('DEM')\n",
    "axs[1].set_title('Real Water Depth (m)')\n",
    "axs[2].set_title('Predicted Water Depth (m)')\n",
    "axs[3].set_title('Difference (m)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb6535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
